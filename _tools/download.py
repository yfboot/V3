import asyncio
import json
import os
from urllib.parse import urlparse, unquote
import re
import sys
import time

import aiohttp
import yaml

import config


class Emoji:
    """æ ¹æ®ç»ˆç«¯èƒ½åŠ›è‡ªåŠ¨é€‰æ‹© emoji æˆ– ASCII æ›¿ä»£ç¬¦ã€‚"""

    _MAP = {
        "âœ…": "[OK]", "âŒ": "[X]", "âš ï¸": "[!]", "ğŸ”": "[?]",
        "ğŸ“¦": "[PKG]", "ğŸ‰": "[YAY]", "ğŸ”§": "[TOOL]", "â±ï¸": "[TIME]",
        "ğŸ“Š": "[STAT]", "ğŸ“": "[LOG]", "ğŸš«": "[BLOCK]", "ğŸ”": "[RETRY]",
    }

    def __init__(self):
        self.supports_emoji = self._detect()

    @staticmethod
    def _detect() -> bool:
        if getattr(sys, 'frozen', False):
            return False
        if config.IS_WIN:
            return bool(os.environ.get('WT_SESSION') or os.environ.get('TERM_PROGRAM'))
        return True

    def get(self, char: str) -> str:
        return char if self.supports_emoji else self._MAP.get(char, "[?]")


emoji = Emoji()

# ===== é…ç½®ï¼ˆæ¥è‡ª config.pyï¼‰ =====
PACKAGES_PATH = "./packages"
MAX_RETRIES = 3
TIMEOUT = config.DOWNLOAD_TIMEOUT
CONCURRENT_LIMIT = config.DOWNLOAD_CONCURRENCY
CUSTOM_REGISTRY = config.DOWNLOAD_REGISTRY
DOWNLOAD_LOG = "logs/download.log"

# ===== å·¥å…·å‡½æ•° =====
def replace_registry(url, use_custom=True):
    """å°† tarball URL çš„æºæ›¿æ¢ä¸ºé…ç½®çš„é•œåƒã€‚
    é€šè¿‡æå– URL è·¯å¾„éƒ¨åˆ†é‡å»ºï¼Œå…¼å®¹ä»»ä½•æ¥æºï¼ˆnpmjs / npmmirror / æœ¬åœ° 127.0.0.1 ç­‰ï¼‰ã€‚"""
    if not use_custom or "/-/" not in url:
        return url
    parsed = urlparse(url)
    return CUSTOM_REGISTRY.rstrip("/") + parsed.path

# ===== å®‰å…¨è·¯å¾„å¤„ç† =====
def sanitize_path(path):
    """å°†éæ³•è·¯å¾„å­—ç¬¦æ›¿æ¢ä¸ºå®‰å…¨å­—ç¬¦"""
    return re.sub(r'[<>:"/\\|?*\x00-\x1F()@]', '_', path)

def clean_package_url(url):
    """æ¸…ç†URLä¸­çš„åµŒå¥—ä¾èµ–ä¿¡æ¯"""
    # åŸºæœ¬npmåŒ…URLæ ¼å¼: registry/name/-/name-version.tgz
    parsed = urlparse(url)
    path = parsed.path
    
    # å¦‚æœæ²¡æœ‰åµŒå¥—æ‹¬å·ï¼Œç›´æ¥è¿”å›
    if '(' not in path and ')' not in path:
        return url
    
    try:
        # æå–ä¸»è¦éƒ¨åˆ†
        # å¯¹äº /pkg/-/pkg-1.0.0(dep1)(dep2).tgz æå–æˆ /pkg/-/pkg-1.0.0.tgz
        main_path = re.sub(r'(\([^()]*(?:\([^()]*\)[^()]*)*\))+\.tgz$', '.tgz', path)
        
        # å¦‚æœæ¸…ç†å¤±è´¥ï¼Œå°è¯•æ›´å¤æ‚çš„æ–¹æ³•
        if '(' in main_path:
            # è¯†åˆ«ä½œç”¨åŸŸåŒ… /@scope/pkg/-/pkg-1.0.0(...)
            if '/@' in path and '/-/' in path:
                scope_end = path.find('/-/')
                if scope_end > 0:
                    scope_part = path[:scope_end]  # ä¾‹å¦‚ /@scope/pkg
                    file_part = path[scope_end+3:] # ä¾‹å¦‚ pkg-1.0.0(...).tgz
                    if '(' in file_part:
                        # æå–ç‰ˆæœ¬å·
                        pkg_name = scope_part.split('/')[-1]
                        version_match = re.match(f'{pkg_name}-([0-9]+\\.[0-9]+\\.[0-9]+[^()]*)\\(', file_part)
                        if version_match:
                            version = version_match.group(1)
                            main_path = f"{scope_part}/-/{pkg_name}-{version}.tgz"
            else:
                # å¤„ç†æ™®é€šåŒ… /pkg/-/pkg-1.0.0(...)
                base_path_match = re.match(r'^(/[^/]+/-/[^/]+-\d+\.\d+\.\d+)', path)
                if base_path_match:
                    main_path = f"{base_path_match.group(1)}.tgz"
                else:
                    # æœ€åå°è¯•
                    pkg_path = path.split('/-/')[0] if '/-/' in path else ''
                    file_name = os.path.basename(path)
                    version_match = re.match(r'.*?-(\d+\.\d+\.\d+[^()]*?)[\(\.]', file_name)
                    if version_match and pkg_path:
                        pkg_name = os.path.basename(pkg_path)
                        version = version_match.group(1)
                        main_path = f"{pkg_path}/-/{pkg_name}-{version}.tgz"
        
        # é‡å»ºURL
        cleaned_url = f"{parsed.scheme}://{parsed.netloc}{main_path}"
        if url != cleaned_url:
            print(f"{emoji.get('ğŸ”§')} ä¿®æ­£åŒ…URL: {url.split('/')[-1]} -> {cleaned_url.split('/')[-1]}")
        return cleaned_url
    except Exception as e:
        print(f"{emoji.get('âš ï¸')} URLæ¸…ç†å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹URL: {url}, é”™è¯¯: {str(e)[:100]}")
        return url
        
# ===== å¤„ç†åŒ…URL =====
def add_url_to_download(urls_set, url):
    """æ·»åŠ URLåˆ°ä¸‹è½½é›†åˆï¼Œå¤„ç†URLæ ¼å¼é—®é¢˜"""
    # æ¸…ç†åµŒå¥—ä¾èµ–ä¿¡æ¯
    clean_url = clean_package_url(url)
    urls_set.add(clean_url)

# ===== ä» lock ä¸­æ”¶é›†â€œæœ‰ resolvedâ€çš„åŒ…åï¼ˆç”¨äºæ’é™¤å·²å­˜åœ¨çš„ peer/optionalï¼‰ =====
def _npm_lock_resolved_names(lockfile_data):
    """è¿”å› package-lock ä¸­å·²æœ‰ resolved çš„åŒ…åé›†åˆã€‚
    æ”¯æŒåµŒå¥—è·¯å¾„ï¼šnode_modules/a/node_modules/@scope/b -> æå– @scope/bã€‚
    """
    names = set()
    if 'packages' not in lockfile_data:
        return names
    for pkg_path, pkg_info in lockfile_data['packages'].items():
        if not pkg_path or not isinstance(pkg_info, dict) or 'resolved' not in pkg_info:
            continue
        # å–æœ€åä¸€æ®µ node_modules/ ä¹‹åçš„éƒ¨åˆ†ä½œä¸ºåŒ…å
        # node_modules/a/node_modules/@scope/b -> @scope/b
        parts = pkg_path.split('node_modules/')
        name = parts[-1].strip('/') if parts else ''
        if name:
            names.add(name)
    return names


def _parse_version_tuple(version_str):
    """å°† 4.6.7 æˆ– 4.6.7-beta.1 è§£æä¸º (4, 6, 7) ç”¨äºæ¯”è¾ƒï¼Œé¢„å‘å¸ƒåªå–æ•°å­—éƒ¨åˆ†ã€‚"""
    m = re.match(r'^(\d+)\.(\d+)\.(\d+)', str(version_str).strip())
    if m:
        return (int(m.group(1)), int(m.group(2)), int(m.group(3)))
    return (0, 0, 0)


def _version_satisfies_range(version_str, range_str):
    """åˆ¤æ–­ version æ˜¯å¦æ»¡è¶³ npm semver rangeã€‚
    æ”¯æŒ: *, x, ^, ~, >=, >, <=, <, =, ||, çœç•¥ minor/patch ç®€å†™(^4, >=2, 1.x)ã€‚
    """
    v = _parse_version_tuple(version_str)
    range_str = (range_str or '').strip()

    # é€šé…ç¬¦
    if not range_str or range_str in ('*', 'x', 'X', 'latest'):
        return True

    # || åˆ†éš”ï¼šä»»ä¸€æ»¡è¶³
    if '||' in range_str:
        return any(_version_satisfies_range(version_str, p.strip())
                   for p in range_str.split('||'))

    # åŒ¹é…ä¸€ä¸ªæ¡ä»¶: å¯é€‰å‰ç¼€ + ä¸»ç‰ˆæœ¬å·[.æ¬¡ç‰ˆæœ¬å·[.è¡¥ä¸å·]]
    m = re.match(
        r'^(\^|~|>=|>|<=|<|=)?\s*(\d+)(?:\.(\d+|[xX*]))?(?:\.(\d+|[xX*]))?',
        range_str,
    )
    if not m:
        return False

    prefix = m.group(1) or ''
    major = int(m.group(2))
    minor_raw, patch_raw = m.group(3), m.group(4)
    has_minor = minor_raw is not None and minor_raw not in ('x', 'X', '*')
    has_patch = patch_raw is not None and patch_raw not in ('x', 'X', '*')
    minor = int(minor_raw) if has_minor else 0
    patch = int(patch_raw) if has_patch else 0
    b = (major, minor, patch)

    def _ok():
        if prefix == '^':
            # ^major: >= major.0.0 < (major+1).0.0   (major > 0)
            # ^0.minor: >= 0.minor.0 < 0.(minor+1).0 (minor > 0)
            # ^0.0.patch: ç²¾ç¡®åŒ¹é…
            if major > 0:
                return v >= b and v[0] == major
            if has_minor and minor > 0:
                return v >= b and v[0] == 0 and v[1] == minor
            if has_patch:
                return v == b
            return v[0] == major
        if prefix == '~':
            # ~major.minor[.patch]: >= b < major.(minor+1).0
            # ~major: >= major.0.0 < (major+1).0.0
            if has_minor:
                return v >= b and v[0] == major and v[1] == minor
            return v >= b and v[0] == major
        if prefix == '>=':
            return v >= b
        if prefix == '>':
            return v > b
        if prefix == '<=':
            return v <= b
        if prefix == '<':
            return v < b
        if prefix == '=':
            return v == b
        # æ— å‰ç¼€
        if not has_minor:
            return v[0] == major          # "2" â†’ ä»»æ„ 2.x.x
        if not has_patch:
            return v[0] == major and v[1] == minor  # "1.2" â†’ ä»»æ„ 1.2.x
        return v == b                     # ç²¾ç¡®åŒ¹é…

    ok = _ok()
    # ç©ºæ ¼åˆ†éš”çš„åç»­æ¡ä»¶ï¼ˆå¦‚ ">=1 <3"ï¼‰ï¼šå…¨éƒ¨æ»¡è¶³
    rest = range_str[m.end():].strip()
    if rest and ok:
        return _version_satisfies_range(version_str, rest)
    return ok


def _pick_best_version(versions_dict, range_str):
    """ä» versions çš„ key ä¸­é€‰ä¸€ä¸ªæ»¡è¶³ range çš„æœ€é«˜ç‰ˆæœ¬ã€‚"""
    candidates = []
    for ver in versions_dict:
        if _version_satisfies_range(ver, range_str):
            candidates.append((_parse_version_tuple(ver), ver))
    if not candidates:
        return None
    candidates.sort(key=lambda x: x[0], reverse=True)
    return candidates[0][1]


# ===== ä» lock ä¸­æ”¶é›†â€œæœªå¸¦ resolvedâ€çš„ä¾èµ–ï¼ˆä»… npm lock v2/v3ï¼‰ =====
def collect_missing_peer_optional_from_lock(lockfile_data, existing_urls):
    """
    ä» package-lock.json çš„ packages é‡Œæ”¶é›†æ‰€æœ‰ peerDependenciesã€optionalDependenciesã€dependencies
    ä¸­å‡ºç°çš„ä¾èµ–ï¼›è‹¥è¯¥ä¾èµ–åœ¨ lock ä¸­æ²¡æœ‰è‡ªå·±çš„ resolved æ¡ç›®ï¼ˆæˆ–æœªå‡ºç°åœ¨ existing_urls ä¸­ï¼‰ï¼Œ
    åˆ™è§†ä¸ºç¼ºå¤±ï¼Œè¿”å› [(name, range), ...]ã€‚è¿™æ ·å³ä½¿ lock å›  npm ç‰ˆæœ¬/å®‰è£…æ–¹å¼æœªç”ŸæˆæŸåŒ…çš„
    resolvedï¼Œåªè¦æŸåŒ…å£°æ˜äº†è¯¥ä¾èµ–ï¼Œä¹Ÿä¼šè¢«è¡¥ä¸‹ï¼ˆå¦‚ @types/event-emitterï¼‰ã€‚
    existing_urls: å½“å‰å·²æ”¶é›†åˆ°çš„ tarball URL åˆ—è¡¨ï¼Œç”¨äºè§£æå‡ºå·²å­˜åœ¨çš„åŒ…åï¼Œé¿å…é‡å¤ã€‚
    """
    if 'packages' not in lockfile_data:
        return []
    resolved_names = _npm_lock_resolved_names(lockfile_data)
    for url in (existing_urls or []):
        try:
            name, _ = extract_package_info(url)
            if name:
                resolved_names.add(name)
        except Exception:
            pass
    missing = []
    seen = set()
    # åŒæ—¶æ£€æŸ¥ dependenciesï¼Œé¿å…å›  lock æœªåŒ…å«æŸåŒ… resolved è€Œæ¼ä¸‹ï¼ˆå¦‚éƒ¨åˆ† npm/install åœºæ™¯ï¼‰
    for pkg_path, pkg_info in lockfile_data['packages'].items():
        if not isinstance(pkg_info, dict):
            continue
        for key in ('peerDependencies', 'optionalDependencies', 'dependencies'):
            deps = pkg_info.get(key)
            if not isinstance(deps, dict):
                continue
            for dep_name, range_spec in deps.items():
                dep_name = (dep_name or '').strip()
                if not dep_name or dep_name in resolved_names:
                    continue
                # lock é‡Œ dependencies çš„å€¼å¯èƒ½æ˜¯ç‰ˆæœ¬æˆ– range å­—ç¬¦ä¸²
                spec_str = (range_spec if isinstance(range_spec, str) else str(range_spec or 'latest')).strip()
                spec = (dep_name, spec_str)
                if spec in seen:
                    continue
                seen.add(spec)
                missing.append(spec)
    return missing


# ===== é€šè¿‡ registry å°† (name, range) è§£æä¸º tarball URL =====
async def resolve_spec_to_tarball_url(session, name, range_spec, registry):
    """è¯·æ±‚ registry åŒ…å…ƒæ•°æ®ï¼Œè§£æ range å¾—åˆ°å…·ä½“ç‰ˆæœ¬ï¼Œè¿”å› tarball URLï¼›å¤±è´¥è¿”å› Noneã€‚"""
    registry = registry.rstrip('/')
    try:
        if name.startswith('@'):
            scope, pkg_name = name.split('/', 1)
            pkg_url = f"{registry}/{scope}%2F{pkg_name}"
        else:
            pkg_url = f"{registry}/{name}"
        async with session.get(pkg_url, timeout=aiohttp.ClientTimeout(total=15)) as resp:
            if resp.status != 200:
                return None
            data = await resp.json()
    except Exception:
        return None
    versions = data.get('versions') or {}
    if not versions:
        return None
    range_str = (range_spec or '').strip()
    if not range_str:
        # æ— ç‰ˆæœ¬çº¦æŸæ—¶ï¼Œä¸ä¸‹è½½ï¼ˆé¿å…æ‹‰å–ä¸å…¼å®¹çš„ latest ç‰ˆæœ¬ï¼‰
        return None
    version = _pick_best_version(versions, range_str)
    if not version:
        # range æ— æ³•åŒ¹é…ä»»ä½•å·²å‘å¸ƒç‰ˆæœ¬ï¼Œæ”¾å¼ƒè€Œé fallback åˆ° latestï¼ˆé˜²æ­¢ç‰ˆæœ¬å†²çªï¼‰
        return None
    if version not in versions:
        return None
    dist = versions[version].get('dist') or {}
    tarball = dist.get('tarball')
    if not tarball or not tarball.startswith('http'):
        return None
    return replace_registry(tarball)


# ===== æå–ä¾èµ–å‡½æ•° =====
def extract_npm_urls(lockfile_data):
    urls = set()

    def recurse_deps(deps, is_npm7=False):
        if not isinstance(deps, dict):
            return
            
        for name, info in deps.items():
            if isinstance(info, dict):
                # å¤„ç†npm7+æ ¼å¼ (package-lock.json v2+)
                if is_npm7 and 'resolved' in info:
                    resolved_url = info['resolved']
                    if resolved_url.startswith('http'):
                        add_url_to_download(urls, replace_registry(resolved_url))
                
                # å¤„ç†å¸¸è§„ä¾èµ–
                if 'resolved' in info and info['resolved'].startswith('http'):
                    add_url_to_download(urls, replace_registry(info['resolved']))
                    
                # å¤„ç†å­ä¾èµ–
                if 'dependencies' in info:
                    recurse_deps(info['dependencies'], is_npm7)
                    
                # å¤„ç†requireèŠ‚ç‚¹
                if 'requires' in info and not is_npm7:
                    # npm <= 6 æœ‰æ—¶ä¼šå°†ä¾èµ–æ”¾åœ¨requiresèŠ‚ç‚¹
                    for req_name, req_version in info['requires'].items():
                        # å°è¯•åœ¨çˆ¶èŠ‚ç‚¹æ‰¾resolved URL
                        for parent_name, parent_info in deps.items():
                            if isinstance(parent_info, dict) and parent_name == req_name and 'resolved' in parent_info:
                                add_url_to_download(urls, replace_registry(parent_info['resolved']))

    # å¤„ç† package-lock.json v2 (npm 7+) æ ¼å¼
    if 'packages' in lockfile_data:
        is_npm7 = True
        for pkg_path, pkg_info in lockfile_data['packages'].items():
            if pkg_path == '':  # è·³è¿‡æ ¹åŒ…
                continue
                
            if isinstance(pkg_info, dict) and 'resolved' in pkg_info:
                resolved_url = pkg_info['resolved']
                if resolved_url.startswith('http'):
                    add_url_to_download(urls, replace_registry(resolved_url))

    # å¤„ç†ä¼ ç»Ÿ package-lock.json æ ¼å¼
    if 'dependencies' in lockfile_data:
        recurse_deps(lockfile_data['dependencies'], 'packages' in lockfile_data)
        
    if 'devDependencies' in lockfile_data:
        recurse_deps(lockfile_data['devDependencies'], 'packages' in lockfile_data)
    if 'optionalDependencies' in lockfile_data:
        recurse_deps(lockfile_data['optionalDependencies'], 'packages' in lockfile_data)
        
    return list(urls)

def extract_pnpm_urls(lockfile_data):
    urls = set()
    workspace_packages = set()
    
    # å°è¯•è¯»å– pnpm-workspace.yaml ä»¥è·å–å·¥ä½œåŒºä¿¡æ¯
    try:
        if os.path.exists('pnpm-workspace.yaml'):
            with open('pnpm-workspace.yaml', encoding='utf-8') as f:
                workspace_data = yaml.safe_load(f)
                if workspace_data and 'packages' in workspace_data:
                    for pattern in workspace_data['packages']:
                        # è®°å½•å¯èƒ½çš„å·¥ä½œåŒºå‰ç¼€
                        if pattern.endswith('/*'):
                            workspace_packages.add(pattern[:-2])
            print(f"{emoji.get('âœ…')} å·²è¯†åˆ«å·¥ä½œåŒºç›®å½•: {', '.join(workspace_packages)}")
    except Exception as e:
        print(f"{emoji.get('âš ï¸')} è¯»å– pnpm-workspace.yaml å¤±è´¥: {str(e)}")
    
    # åˆ¤æ–­æ˜¯å¦ä¸ºå·¥ä½œåŒºåŒ…
    def is_workspace_package(pkg_name, version_info):
        # ç›´æ¥æ£€æŸ¥ç‰ˆæœ¬æ˜¯å¦ä¸º workspace: æˆ– link: å¼€å¤´
        if isinstance(version_info, str) and (version_info.startswith('workspace:') or version_info.startswith('link:')):
            return True
            
        # æ£€æŸ¥å¤æ‚å¯¹è±¡çš„ specifier å’Œ version å­—æ®µ
        if isinstance(version_info, dict):
            specifier = version_info.get('specifier', '')
            version = version_info.get('version', '')
            
            if (isinstance(specifier, str) and specifier.startswith('workspace:')) or \
               (isinstance(version, str) and version.startswith('link:')):
                return True
                
        return False
    
    # å¤„ç†åŒ…ç›´æ¥URLæˆ–æ„é€ URL
    def add_package_url(pkg_name, version, resolved=None):
        # å·²ç»æœ‰æ˜ç¡®çš„resolved URL
        if resolved and resolved.startswith('http'):
            add_url_to_download(urls, replace_registry(resolved))
            return True
            
        # è·³è¿‡workspace packageså’Œæœ¬åœ°é“¾æ¥
        if isinstance(version, str):
            # æ£€æŸ¥æ˜ç¡®çš„workspaceæˆ–linkå‰ç¼€
            if version.startswith('link:') or version.startswith('workspace:'):
                print(f"{emoji.get('âš ï¸')} è·³è¿‡å·¥ä½œåŒºåŒ…ï¼š{pkg_name}@{version}")
                return False
                
            # æ£€æŸ¥åŒ…æ˜¯å¦åœ¨å·¥ä½œåŒºè·¯å¾„ä¸­
            for workspace in workspace_packages:
                if version.startswith(f"link:{workspace}/"):
                    print(f"{emoji.get('âš ï¸')} è·³è¿‡å·¥ä½œåŒºåŒ…ï¼š{pkg_name}@{version}")
                    return False
            
        # å¤„ç†scopedåŒ…å (@scope/package)
        if pkg_name.startswith('@'):
            try:
                scope, name = pkg_name.split('/', 1)
                # æ„å»ºå®Œæ•´URLï¼Œä¿ç•™ä½œç”¨åŸŸ
                url = f"{CUSTOM_REGISTRY}/{pkg_name}/-/{name}-{version}.tgz"
            except Exception as e:
                print(f"{emoji.get('âš ï¸')} å¤„ç†ä½œç”¨åŸŸåŒ…å‡ºé”™: {pkg_name}@{version}, é”™è¯¯: {str(e)}")
                # é™çº§å¤„ç†
                url = f"{CUSTOM_REGISTRY}/{pkg_name}/-/{pkg_name.split('/')[-1]}-{version}.tgz"
        else:
            url = f"{CUSTOM_REGISTRY}/{pkg_name}/-/{pkg_name}-{version}.tgz"
            
        add_url_to_download(urls, url)
        return True

    # é€’å½’å¤„ç†packageséƒ¨åˆ†
    def process_packages():
        if 'packages' not in lockfile_data:
            return
            
        for path, pkg_info in lockfile_data['packages'].items():
            # å¿½ç•¥æ ¹åŒ…
            if path == '':
                continue
                
            # æå–åŒ…åå’Œç‰ˆæœ¬å·
            if path.startswith('node_modules/'):
                pkg_name = path.replace('node_modules/', '')
            else:
                pkg_name = path
                
            # è·³è¿‡å·¥ä½œåŒºåŒ…
            if pkg_info and is_workspace_package(pkg_name, pkg_info):
                print(f"{emoji.get('âš ï¸')} è·³è¿‡å·¥ä½œåŒºåŒ…ï¼š{pkg_name}@{str(pkg_info).split(',')[0] if isinstance(pkg_info, dict) else pkg_info}")
                continue
                
            # å¤„ç†å·²è§£æçš„URL
            if pkg_info and isinstance(pkg_info, dict):
                version = pkg_info.get('version')
                resolved = pkg_info.get('resolved')
                
                # å¦‚æœæœ‰æ˜ç¡®çš„resolvedå­—æ®µï¼Œç›´æ¥ä½¿ç”¨å®ƒ
                if resolved:
                    add_package_url(pkg_name, version, resolved)
                elif version:
                    # æ¸…ç†ç‰ˆæœ¬å·ä¸­çš„æ‹¬å·å†…å®¹
                    if isinstance(version, str):
                        # è·³è¿‡å·¥ä½œåŒºé“¾æ¥
                        if version.startswith('link:') or version.startswith('workspace:'):
                            print(f"{emoji.get('âš ï¸')} è·³è¿‡å·¥ä½œåŒºåŒ…ï¼š{pkg_name}@{version}")
                            continue
                            
                        version_match = re.match(r'^([^()]+)', version)
                        if version_match:
                            version = version_match.group(1).strip()
                    add_package_url(pkg_name, version)
    
    # é€’å½’å¤„ç†ä¾èµ–éƒ¨åˆ†
    def process_dependencies(deps_dict):
        if not deps_dict or not isinstance(deps_dict, dict):
            return
            
        for pkg_name, info in deps_dict.items():
            # è·³è¿‡å·¥ä½œåŒºåŒ…
            if is_workspace_package(pkg_name, info):
                print(f"{emoji.get('âš ï¸')} è·³è¿‡å·¥ä½œåŒºåŒ…ï¼š{pkg_name}@{str(info).split(',')[0] if isinstance(info, dict) else info}")
                continue
                
            if isinstance(info, dict):
                version = info.get('version')
                resolved = info.get('resolved')
                
                if version or resolved:
                    add_package_url(pkg_name, version, resolved)
                
                # é€’å½’å¤„ç†å­ä¾èµ–
                if 'dependencies' in info:
                    process_dependencies(info['dependencies'])
                    
            elif isinstance(info, str):
                # è·³è¿‡å·¥ä½œåŒºåŒ…
                if info.startswith('workspace:') or info.startswith('link:'):
                    print(f"{emoji.get('âš ï¸')} è·³è¿‡å·¥ä½œåŒºåŒ…ï¼š{pkg_name}@{info}")
                    continue
                # ç®€å•çš„ç‰ˆæœ¬å­—ç¬¦ä¸²
                version_match = re.match(r'^([^()]+)', info)
                version = version_match.group(1).strip() if version_match else info
                add_package_url(pkg_name, version)

    # å¤„ç†ä¸»è¦ä¾èµ–éƒ¨åˆ†
    if 'importers' in lockfile_data:
        for path, importer in lockfile_data['importers'].items():
            if isinstance(importer, dict):
                # å¤„ç†æ­£å¸¸ä¾èµ–
                if 'dependencies' in importer:
                    process_dependencies(importer['dependencies'])
                    
                # å¤„ç†å¼€å‘ä¾èµ–
                if 'devDependencies' in importer:
                    process_dependencies(importer['devDependencies'])
                    
                if 'optionalDependencies' in importer:
                    process_dependencies(importer['optionalDependencies'])
    
    # å¤„ç†é¡¶çº§dependencies
    if 'dependencies' in lockfile_data:
        process_dependencies(lockfile_data['dependencies'])
        
    if 'devDependencies' in lockfile_data:
        process_dependencies(lockfile_data['devDependencies'])
    if 'optionalDependencies' in lockfile_data:
        process_dependencies(lockfile_data['optionalDependencies'])
        
    # å¤„ç†packageséƒ¨åˆ†
    process_packages()

    return list(urls)

def extract_yarn_urls(lockfile_data):
    urls = set()
    
    # åŒ¹é…yarn.lockä¸­çš„URL
    resolved_pattern = re.compile(r'"resolved"\s+"(https?://[^"]+)"')
    registry_pattern = re.compile(r'"registry"\s+"(https?://[^"]+)"')
    version_pattern = re.compile(r'"version"\s+"([^"]+)"') 
    name_pattern = re.compile(r'^([@a-zA-Z0-9_-]+(?:/[a-zA-Z0-9_-]+)?)')
    
    lines = lockfile_data.splitlines()
    i = 0
    
    while i < len(lines):
        line = lines[i].strip()
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºåŒ…å£°æ˜è¡Œ
        if line and line.endswith(':'):
            pkg_match = name_pattern.search(line)
            if pkg_match:
                pkg_name = pkg_match.group(1).strip('"\'')
                
                # æŸ¥æ‰¾æ­¤åŒ…çš„versionå’Œresolved
                resolved_url = None
                version = None
                j = i + 1
                
                # æ‰«æåˆ°ä¸‹ä¸€ä¸ªåŒ…å£°æ˜å‰æˆ–æ–‡ä»¶ç»“æŸ
                while j < len(lines) and not (lines[j].strip() and lines[j].strip().endswith(':')):
                    resolved_match = resolved_pattern.search(lines[j])
                    if resolved_match:
                        resolved_url = resolved_match.group(1)
                        if resolved_url.startswith('http'):
                            add_url_to_download(urls, replace_registry(resolved_url))
                            
                    # å¦‚æœæ²¡æœ‰resolvedä½†æœ‰versionå’Œregistryï¼Œå°è¯•æ„é€ URL
                    if not resolved_url:
                        version_match = version_pattern.search(lines[j])
                        if version_match:
                            version = version_match.group(1)
                            
                        registry_match = registry_pattern.search(lines[j])
                        if registry_match and version:
                            registry = registry_match.group(1).rstrip('/')
                            # æ„é€ å¯èƒ½çš„URLï¼Œæ­£ç¡®å¤„ç†ä½œç”¨åŸŸåŒ…
                            if pkg_name.startswith('@'):
                                scope, name = pkg_name.split('/', 1)
                                potential_url = f"{registry}/{pkg_name}/-/{name}-{version}.tgz"
                            else:
                                potential_url = f"{registry}/{pkg_name}/-/{pkg_name}-{version}.tgz"
                            add_url_to_download(urls, replace_registry(potential_url))
                            
                    j += 1
                
                # å¦‚æœç‰ˆæœ¬å·å­˜åœ¨ä½†æ²¡æœ‰resolved URLæˆ–registryï¼Œå°è¯•ä½¿ç”¨é»˜è®¤registry
                if version and not resolved_url:
                    if pkg_name.startswith('@'):
                        scope, name = pkg_name.split('/', 1)
                        add_url_to_download(urls, f"{CUSTOM_REGISTRY}/{pkg_name}/-/{name}-{version}.tgz")
                    else:
                        add_url_to_download(urls, f"{CUSTOM_REGISTRY}/{pkg_name}/-/{pkg_name}-{version}.tgz")
                
                i = j - 1  # è°ƒæ•´ä¸»å¾ªç¯ç´¢å¼•
        
        i += 1
        
    return list(urls)

# ===== æå–åŒ…åå’Œç‰ˆæœ¬å· =====
def extract_package_info(url):
    """ä»URLä¸­æå–åŒ…åå’Œç‰ˆæœ¬å·"""
    try:
        parsed = urlparse(url)
        path = unquote(parsed.path)
        
        # å°è¯•æå–åŒ…å
        if '/-/' in path:
            # æ ¼å¼: /pkg/-/pkg-1.0.0.tgz æˆ– /@scope/pkg/-/pkg-1.0.0.tgz
            parts = path.split('/-/')
            pkg_part = parts[0].strip('/')
            
            # æå–ç‰ˆæœ¬å·
            file_name = os.path.basename(path)
            if pkg_part.startswith('@'):
                # ä½œç”¨åŸŸåŒ… @scope/pkg
                scope, name = pkg_part.split('/', 1)
                version_match = re.search(f'{name}-([0-9]+\\.[0-9]+\\.[0-9]+[^)]*?)(\\.tgz|$)', file_name)
            else:
                # æ™®é€šåŒ…
                name = pkg_part
                version_match = re.search(f'{name}-([0-9]+\\.[0-9]+\\.[0-9]+[^)]*?)(\\.tgz|$)', file_name)
                
            if version_match:
                version = version_match.group(1)
                return pkg_part, version
        
        # å¤‡ç”¨æ–¹æ³•ï¼šç›´æ¥ä»æ–‡ä»¶åçŒœæµ‹
        file_name = os.path.basename(path)
        name_version_match = re.match(r'(.+?)-([0-9]+\.[0-9]+\.[0-9]+[^)]*?)(\.tgz|$)', file_name)
        if name_version_match:
            name = name_version_match.group(1)
            version = name_version_match.group(2)
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºä½œç”¨åŸŸåŒ…
            if '/-/' in path and '@' in path:
                parts = path.split('/-/')
                if parts and parts[0].strip('/'):
                    return parts[0].strip('/'), version
            
            return name, version

    except Exception:
        pass

    # æ— æ³•æå–æ—¶è¿”å›æ–‡ä»¶å
    return os.path.basename(unquote(url)), "æœªçŸ¥ç‰ˆæœ¬"

# ===== ä¸‹è½½å‡½æ•° =====
async def download_file(session, url, semaphore):
    """ä½¿ç”¨ä¿¡å·é‡é™åˆ¶å¹¶å‘ä¸‹è½½æ•°é‡"""
    # ç¡®ä¿URLæ ¼å¼æ­£ç¡®
    url = clean_package_url(url)
    mirror_url = replace_registry(url)
    official_url = url.replace(CUSTOM_REGISTRY, "https://registry.npmjs.org")

    async with semaphore:  # ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘
        for attempt in range(MAX_RETRIES):
            try:
                current_url = mirror_url if attempt < MAX_RETRIES - 1 else official_url
                parsed = urlparse(current_url)
                file_name = os.path.basename(unquote(parsed.path))
                # ç¡®ä¿æ–‡ä»¶åå®‰å…¨ï¼Œç›´æ¥ä¿å­˜åˆ°ç›®æ ‡æ–‡ä»¶å¤¹
                safe_file_name = sanitize_path(file_name)
                file_path = os.path.join(PACKAGES_PATH, safe_file_name)

                # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
                os.makedirs(PACKAGES_PATH, exist_ok=True)

                headers = {
                    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0 Safari/537.36"
                }

                async with session.get(current_url, timeout=TIMEOUT, headers=headers) as response:
                    response.raise_for_status()
                    with open(file_path, 'wb') as f:
                        while True:
                            chunk = await response.content.read(8192)  # å¢å¤§è¯»å–å—å¤§å°
                            if not chunk:
                                break
                            f.write(chunk)

                return None
            except aiohttp.ClientResponseError as e:
                if e.status == 404 and mirror_url != official_url:
                    # å¦‚æœæ˜¯404é”™è¯¯ï¼Œç«‹å³å°è¯•å®˜æ–¹æº
                    print(f"{emoji.get('âš ï¸')} {mirror_url} æœªæ‰¾åˆ°, å°è¯•å®˜æ–¹æº {official_url}")
                    mirror_url = official_url
                    continue
                elif attempt < MAX_RETRIES - 1:
                    await asyncio.sleep(1)
                else:
                    print(f"{emoji.get('âŒ')} ä¸‹è½½å¤±è´¥ ({e.status}): {current_url}")
                    return (url, official_url, f"HTTP {e.status}")
            except Exception as e:
                if attempt < MAX_RETRIES - 1:
                    print(f"{emoji.get('ğŸ”')} ç¬¬ {attempt+1} æ¬¡å¤±è´¥ï¼Œæ­£åœ¨é‡è¯•ï¼š{current_url}ï¼Œé”™è¯¯: {str(e)[:100]}")
                    await asyncio.sleep(1)
                else:
                    print(f"{emoji.get('âŒ')} ä¸‹è½½å¤±è´¥ï¼š{current_url} â†’ å¯å°è¯•æ‰‹åŠ¨ä¸‹è½½ï¼š{official_url}")
                    print(f"   é”™è¯¯ä¿¡æ¯: {str(e)[:100]}")
                    return (url, official_url, str(e)[:500])

# ===== ä¸»ç¨‹åº =====
async def main():
    # ç«‹å³è¾“å‡ºï¼Œé¿å…ç”¨æˆ·è¯¯ä»¥ä¸ºå¡ä½ï¼ˆé…åˆ line_buffering æˆ– flushï¼‰
    print("NPM ä¾èµ–ä¸‹è½½å·¥å…· æ­£åœ¨å¯åŠ¨...", flush=True)

    print(f"""
{emoji.get("ğŸ“¦")} NPM ä¾èµ–ä¸‹è½½å·¥å…·
============================
{emoji.get("âœ…")} åŒ…ä¿å­˜ç›®å½•: {PACKAGES_PATH}
{emoji.get("âœ…")} å¹¶å‘ä¸‹è½½æ•°: {CONCURRENT_LIMIT}
{emoji.get("âœ…")} ä¸‹è½½è¶…æ—¶ç§’: {TIMEOUT}
{emoji.get("âœ…")} é•œåƒæºåœ°å€: {CUSTOM_REGISTRY}
============================
    """, flush=True)

    extract_func = None
    data = None

    # ç¡®ä¿ä¸‹è½½ç›®å½•å­˜åœ¨
    os.makedirs(PACKAGES_PATH, exist_ok=True)
    
    print(f"{emoji.get('ğŸ”')} æ£€æµ‹é”æ–‡ä»¶...", flush=True)

    if os.path.exists('package-lock.json'):
        print(f"{emoji.get('âœ…')} æ£€æµ‹åˆ° npm é”æ–‡ä»¶ (package-lock.json)", flush=True)
        print("æ­£åœ¨è¯»å– package-lock.jsonï¼ˆæ–‡ä»¶è¾ƒå¤§æ—¶å¯èƒ½éœ€è¦å‡ ç§’ï¼‰...", flush=True)
        try:
            with open("package-lock.json", encoding='utf-8') as f:
                data = json.load(f)
            extract_func = extract_npm_urls
        except json.JSONDecodeError:
            print(f"{emoji.get('âŒ')} package-lock.json æ ¼å¼é”™è¯¯!")
            return
    elif os.path.exists('pnpm-lock.yaml'):
        print(f"{emoji.get('âœ…')} æ£€æµ‹åˆ° pnpm é”æ–‡ä»¶ (pnpm-lock.yaml)")
        try:
            with open("pnpm-lock.yaml", encoding='utf-8') as f:
                data = yaml.safe_load(f)
            extract_func = extract_pnpm_urls
        except yaml.YAMLError:
            print(f"{emoji.get('âŒ')} pnpm-lock.yaml æ ¼å¼é”™è¯¯!")
            return
    elif os.path.exists('yarn.lock'):
        print(f"{emoji.get('âœ…')} æ£€æµ‹åˆ° yarn é”æ–‡ä»¶ (yarn.lock)")
        try:
            with open("yarn.lock", encoding='utf-8') as f:
                data = f.read()
            extract_func = extract_yarn_urls
        except Exception as e:
            print(f"{emoji.get('âŒ')} yarn.lock è¯»å–é”™è¯¯: {str(e)}")
            return
    else:
        print(f"{emoji.get('âŒ')} é”™è¯¯: æœªæ‰¾åˆ° package-lock.json, pnpm-lock.yaml æˆ– yarn.lock!")
        return

    print(f"{emoji.get('ğŸ“¦')} è§£æä¾èµ–...")
    urls = list(extract_func(data))
    
    # ä» package-lock ä¸­è¡¥ä¸‹æœªå¸¦ resolved çš„ peer/optional ä¾èµ–ï¼ˆä»… npm lockï¼‰
    missing_specs = []
    if extract_func is extract_npm_urls and isinstance(data, dict) and 'packages' in data:
        missing_specs = collect_missing_peer_optional_from_lock(data, urls)
        if missing_specs:
            print(f"{emoji.get('ğŸ”')} å‘ç° lock ä¸­æœªå¸¦ resolved çš„ peer/optional ä¾èµ– {len(missing_specs)} ä¸ªï¼Œå°†å‘ registry è§£æå¹¶åŠ å…¥ä¸‹è½½åˆ—è¡¨")
    
    # ç§»é™¤é‡å¤URLå¹¶æ’åºä»¥æé«˜ç¨³å®šæ€§ï¼ˆè¡¥ä¸‹ peer-from-lock çš„ URL åœ¨ä¸‹é¢ session å†…åˆå¹¶ï¼‰
    unique_urls = sorted(set(urls))
    total_count = len(unique_urls)
    
    if total_count == 0:
        print(f"{emoji.get('âš ï¸')} æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ä¾èµ–é¡¹ã€‚å¯èƒ½æ˜¯é”æ–‡ä»¶æ ¼å¼ä¸æ”¯æŒæˆ–æ²¡æœ‰ä¾èµ–è®°å½•ã€‚")
        return

    # åˆ›å»ºä¿¡å·é‡ä»¥é™åˆ¶å¹¶å‘ä¸‹è½½æ•°é‡
    semaphore = asyncio.Semaphore(CONCURRENT_LIMIT)
    timeout = aiohttp.ClientTimeout(total=TIMEOUT)
    conn = aiohttp.TCPConnector(limit=CONCURRENT_LIMIT)
    
    print(f"{emoji.get('ğŸ”')} å‡†å¤‡ä¸‹è½½ {total_count} ä¸ªåŒ…...")
    print(f"{emoji.get('â±ï¸')} å¼€å§‹ä¸‹è½½...")
    
    start_time = asyncio.get_event_loop().time()
    failed_downloads = []
    
    async with aiohttp.ClientSession(timeout=timeout, connector=conn) as session:
        # è‹¥æœ‰ lock ä¸­ç¼ºå¤±çš„ peer/optionalï¼Œå…ˆå‘ registry è§£æä¸º tarball URL å¹¶åˆå¹¶
        if missing_specs:
            resolved_peer_urls = []
            for name, range_spec in missing_specs:
                u = await resolve_spec_to_tarball_url(session, name, range_spec, CUSTOM_REGISTRY)
                if u:
                    resolved_peer_urls.append(u)
                    print(f"{emoji.get('âœ…')} è§£æ peer/optional: {name}@{range_spec} -> {u.split('/')[-1]}")
                else:
                    print(f"{emoji.get('âš ï¸')} æ— æ³•è§£æ: {name}@{range_spec}")
            if resolved_peer_urls:
                unique_urls = sorted(set(unique_urls) | set(resolved_peer_urls))
                total_count = len(unique_urls)
        
        tasks = [download_file(session, url, semaphore) for url in unique_urls]
        
        # åˆ†æ‰¹å¤„ç†ä»»åŠ¡å¹¶æ˜¾ç¤ºè¿›åº¦
        completed = 0
        for i, batch in enumerate(range(0, len(tasks), 10)):
            batch_tasks = tasks[batch:batch+10]
            batch_results = await asyncio.gather(*batch_tasks)
            
            # æ›´æ–°è¿›åº¦
            completed += len(batch_tasks)
            progress = (completed / total_count) * 100
            print(f"è¿›åº¦: {completed}/{total_count} ({progress:.1f}%)")
            
            # æ”¶é›†å¤±è´¥çš„ä¸‹è½½ (url, official_url, error_info)
            for result in batch_results:
                if result is not None:
                    failed_downloads.append(result)
    
    end_time = asyncio.get_event_loop().time()
    duration = end_time - start_time
    
    success_count = total_count - len(failed_downloads)
    percent = (success_count / total_count) * 100

    print(f"\n{emoji.get('ğŸ“Š')} ä¸‹è½½ç»“æœæŠ¥å‘Šï¼š")
    print(f"æ€»å…±ä¸‹è½½ï¼š{total_count} ä¸ªåŒ…")
    print(f"æˆåŠŸï¼š{success_count} ä¸ªåŒ… ({percent:.1f}%)")
    print(f"è€—æ—¶ï¼š{duration:.1f} ç§’")

    # ä»…å°† 404/å¼‚å¸¸/é”™è¯¯å†™å…¥æ—¥å¿—ï¼Œæ­£å¸¸ä¸‹è½½ä¸å†™å…¥ï¼›æ¯æ¬¡è¿è¡Œè¦†ç›–
    log_dir = os.path.dirname(DOWNLOAD_LOG)
    if log_dir:
        os.makedirs(log_dir, exist_ok=True)
    with open(DOWNLOAD_LOG, "w", encoding="utf-8") as log_file:
        if failed_downloads:
            log_file.write(f"# æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
            log_file.write(f"# å¤±è´¥æ•°: {len(failed_downloads)}\n\n")
            formatted_failures = []
            for item in failed_downloads:
                url, official_url = item[0], item[1]
                error_info = item[2] if len(item) >= 3 else "æœªçŸ¥é”™è¯¯"
                pkg_name, version = extract_package_info(url)
                formatted_failures.append((pkg_name, version, official_url, error_info))
            for pkg_name, version, url, error_info in sorted(formatted_failures, key=lambda x: x[0].lower()):
                log_file.write(f"### {pkg_name}@{version}\n")
                log_file.write(f"é”™è¯¯: {error_info}\n")
                log_file.write(f"ä¸‹è½½é“¾æ¥: {url}\n")
                log_file.write(f"å‘½ä»¤è¡Œ: curl -L \"{url}\" -o \"{os.path.basename(url)}\"\n\n")
        # æ— å¤±è´¥æ—¶ä¸å†™å…¥ä»»ä½•å†…å®¹ï¼Œæ–‡ä»¶ä¸ºç©º

    if not failed_downloads:
        print(f"{emoji.get('ğŸ‰')} å…¨éƒ¨ä¸‹è½½æˆåŠŸï¼")
    else:
        print(f"{emoji.get('âœ…')} æˆåŠŸä¸‹è½½: {success_count} ä¸ªåŒ…")
        print(f"{emoji.get('âŒ')} ä¸‹è½½å¤±è´¥: {len(failed_downloads)} ä¸ªåŒ…")
        print(f"\n{emoji.get('ğŸš«')} å¤±è´¥çš„åŒ…åˆ—è¡¨ï¼ˆè¯·å°è¯•æ‰‹åŠ¨ä¸‹è½½ï¼‰ï¼š")
        for i, item in enumerate(failed_downloads, start=1):
            url, official_url = item[0], item[1]
            error_info = item[2] if len(item) >= 3 else ""
            pkg_name, version = extract_package_info(url)
            print(f"{i}. {pkg_name}@{version}  {error_info}")
            print(f"   â†’ ä¸‹è½½é“¾æ¥: {official_url}")
        print(f"\n{emoji.get('ğŸ“')} 404/é”™è¯¯æ—¥å¿—å·²å†™å…¥ï¼š{DOWNLOAD_LOG}")

if __name__ == '__main__':
    try:
        if config.IS_WIN:
            try:
                os.system("title NPMåŒ…ä¸‹è½½å·¥å…·")
            except Exception:
                pass
        print("\n" + "=" * 40)
        print("     NPM ä¾èµ–åŒ…ä¸‹è½½å·¥å…·")
        print("=" * 40 + "\n")
        asyncio.run(main())
    except KeyboardInterrupt:
        print(f"\n{emoji.get('âš ï¸')} ç”¨æˆ·ä¸­æ–­ï¼Œç¨‹åºé€€å‡º")
    except Exception as e:
        print(f"\n{emoji.get('âŒ')} ç¨‹åºå‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()
    finally:
        if getattr(sys, 'frozen', False):
            try:
                print("\næŒ‰ä»»æ„é”®é€€å‡º...")
                input()
            except Exception:
                try:
                    os.system("pause")
                except Exception:
                    pass